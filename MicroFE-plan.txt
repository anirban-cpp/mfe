#   Set up Git monorepo which will contain all our individual micro FEs.
    This can be done easily with turbo: "npx create-turbo@latest -e with-react-native-web"
    Link: https://github.com/vercel/turbo/tree/main/examples/with-react-native-web

#   Repo will have packages folder. This will have container (which is our main host app)
    Along with that we will have our individual microFEs and shared (state/store).
    Also we can additionally have UI package that may contain any component/sharable code
    from external teams like Phoenix (if needed)

#   Set up github actions scripts (CI/CD) that will look into each sub-project or microFE when we push our code.
    If any changes are made, then we will start a process that will make a production version of that microFE app with webpack

#   Once production build is done, we can upload all our files to Amazon S3

Each microFE step should be independent. So if microFE A is changed only, then only its production build is done and uploaded to S3. Others should be affected because of that
One can be deployed without others being deployed.

Amazon S3 will have the built version of all our different sub-projects/microFEs.

When a file request is made, the file is not served directly from S3, instead it will make a request to Amazon CloudFront (basically a CDN)
Basically Amazon CloudFront will see the incoming request and figure out which files to pull out of our S3 bucket and serve it back to the browser.


For the CI/CD pipeline setup
----------------------------
We can make use of github actions.
Basically whenever any github event is triggered say 'push', 'create PR', 'merge', etc, the webhook will run all workflows associated with this event


##  Workflow for deploying container(host)

Whenever code is pushed to the master branch (primary branch) and there is a commit that contains a change to the container/host folder, the following
steps need to be performed:

->  Change to container folder
->  Install the dependencies
->  Create a production build usig webpack
->  Upload the result to AWS S3

These commands need to be executed in the Github virtual machine by creating a .yml file in .github/workflows

/*
we will be writing our container workflow and using the chrislennon/action-aws-cli@v1.1 action. 
Unfortunately, this is now failing and appears to be no longer maintained.
 A community fork was created to fix the issues which we can use instead:

instead of this:

      - uses: chrislennon/action-aws-cli@v1.1

write this:

      - uses: shinyinc/action-aws-cli@v1.2

This updated action will require an AWS_DEFAULT_REGION key, so, for now, we can just add a placeholder.

      - uses: shinyinc/action-aws-cli@v1.2
      - run: aws s3 sync dist s3://${{ secrets.AWS_S3_BUCKET_NAME }}/container/latest
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ""
*/


Creating the S3 bucket
----------------------
Create the S3 bucket and change the setting to public as we want our app to be available in public domain.
Basically 
->  enable Static Website hosting
->  Hosting Type: Host a static website
->  index document: index.html
->  error document: index.html
->  Go to permissions and uncheck block all public access
->  To allow AWS CloudFront CDN, go to Permissions -> Bucket Policy -> Edit -> Policy Generator

Setup AWS CloudFront (CDN)
--------------------------
->  Search for CloudFront in AWS for Gloal CDN setup
->  Create Distribution
->  Select Web distribution
->  Fill in the details: 
    Origin Settings: Origin Domain Name, 
    Default Cache Behavior Settings: Set Viewer Protocol Policy to edirect HTTP to HTTPS
    Distribution Settngs: SSL Certificate -> Custom SSL Certificate for our yubi domain
-> Create distribution
-> Once the CloudFront distribution is created and the status is saying deployed, click on the distribution -> edit and go to 
    default Root Object and set it to "/container/latest/index.html"
-> Then go to the bottom and click on Yes Edit.
-> Also, go to Error Pages.
    Create Custom Error Response and set the HTTP Error Code to say 403 Forbidden.
    Customize Error Response to Yes
    Provide Response Path as "/container/latest/index.html"
    Change HTTP response code to 200 OK
    Ans click on create
-> Go to the General Tab. Take the Domain Name from there

Update for Generating Keys
--------------------------

Create an IAM user and then generate a key pair for deployment. There is a minor required change to this flow. Instead of being prompted to create a key pair during the IAM user creation, you must first create the IAM user, then, create a key pair associated with that user. AWS has also changed the terminology from Programmatic Access, to Command Line Interface (CLI).

Full updated instructions can be found below:

1. Search for "IAM"

2. Click "Create Individual IAM Users" and click "Manage Users"

3. Click "Add User"

4. Enter any name youâ€™d like in the "User Name" field.

5. Click "Next"

6. Click "Attach Policies Directly"

7. Use the search bar to find and tick AmazonS3FullAccess and CloudFrontFullAccess

8. Click "Next"

9. Click "Create user"

10. Select the IAM user that was just created from the list of users

11. Click "Security Credentials"

12. Scroll down to find "Access Keys"

13. Click "Create access key"

14. Select "Command Line Interface (CLI)"


15. Scroll down and tick the "I understand..." check box and click "Next"

16. Copy and/or download the Access Key ID and Secret Access Key to use for deployment.

Reminder on AWS_DEFAULT_REGION
A few lectures ago we mentioned the need to use a different action and left a placeholder for the AWS_DEFAULT_REGION key.

Let's make sure this gets set correctly now.

In the AWS Dashboard use the Services search bar to find S3 and load its dashboard. Once there, copy the AWS region listed to the right of your bucket:


Then, in your container.yml, paste in the value for the AWS_DEFAULT_REGION like so:

      - uses: shinyinc/action-aws-cli@v1.2
      - run: aws s3 sync dist s3://${{ secrets.AWS_S3_BUCKET_NAME }}/container/latest
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-2

For this go to AWS, and search for servide 'iam'
Go to Users
Give User name for the project's github actions
Give access type as 'Programmatic access'
Next to to Permissions
Add policy for S3 bucket access and cloudFront access
Finally create the user
Copy the Access Key ID and the Secret access key

->  With this Access key ID and Secret access key, go to github Secrets and Variables and create a new repository secret
    Provide the name and value as 'Access Key ID' and 'Secret access key'

-> The AWS_ACCESS_KEY_ID secret should have a name of AWS_ACCESS_KEY_ID and value of what was there for 'Access Key ID'
-> Same for AWS_SECRET_ACCESS_KEY
-> Also for AWS_S3_BUCKET_NAME

Caching issue with AWS CloudFront
---------------------------------

Since CloudFront does caching, it will not check for any file changes in our S# for deployment.
So we have to invalidate thta

->  Go to CloudFront Distributions.
->  Open up our distribution.
->  Create Invalidation.
->  give the path to the index.html file (/container/latest/index.html)
->  A better way is to automate this with our github workflow webhook.
    Command: aws cloudfront create-invalidation --distribution-id ${{ our distribution id }}

This "our distribution id" can be provided from our Github Secrets

Add PRODUCTION_DOMAIN secret to github secrets
Update github workflow and the webpack.prod.js config file such that the outputFile has a publicPath property: publicPath: '/appName/latest/'